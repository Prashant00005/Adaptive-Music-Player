# Adaptive-Music-Player
A web based Music Player App that adapts to the user‚Äôs mood to play songs.
The user‚Äôs mood can depend on number of factors such as time of the day, day of the week, location, etc. This can influence his/her choice of song being played and can decide to continue playing the song, skip it, like or dislike the song. These choices made by the user can again be used to infer his/her mood.
Any mood can be modelled by assigning values between -1 and +1 using the above representation. It can be represented as a two-dimensional vector ùëí, where ùëí ‚â§ 1.
Songs have features such as genre, year of release, singer, average bpm, etc. that can be used to tag them. This information can be combined with user‚Äôs preference of the songs to give more meaningful adaptations.
The final goal of this project is to build a user model that assists to adapt to the user‚Äôs mood and play songs accordingly.

# Mood Inference Engine
Mood Inference Engine plays a major role for the user modelling. The emotions of the user are modelled by this engine. MIE infers the current mood of the person. This is done by collecting the feedback from the user. The client side of the application gets the feedback from the actions (skip, like, dislike, no action) that user performs. This feedback is sent to the MIE. MIE calculates the score for each of the emotions (happy, sad, angry etc) based on the mood of the song played and the actions of the user. Based on the score, the mood of the user is inferred. This is sent to the Song Matching Engine(SME).
Along with the user mood score calculation, it also calculates a weight (Œ±1) based on the type of the music, say, Jazz, RnR, RnB, Pop etc. The type of the user music that the user likes can be obtained from the initial preferences that user makes. These initial preferences are attained from the set of questions asked for the first time the application is used by the user. Œ±1 is also sent to the SME along with mood score to select which type of songs to be played.
A computational model can be used to calculate the mood. The mood is calculated as a function of time. The time refers to the duration for which the user listened to the music before skipping it.

# Song Matching Engine
This is the most salient component of the architecture for song modelling. It has two subdivisions - song search engine and song database. The song search engine is responsible for picking up the song based on user‚Äôs mood. The mood will be conjectured by the Mood Inference Engine and will be given as an input to this engine which will in turn pick up the next relevant song. The songs/tracks will be tagged to various moods in clusters and will be stored in the database. There is a slight chance that if a user likes a particular song there could be a possibility that the system suggests that songs more often as compared to other songs. To nullify this error, the system introduces a noise parameter.
There could be two types of users. One that is moody whose mood changes frequently and likes to listen to songs in the same genre with different moods. And the other user could be experimentative and prefers to listen to new songs irrespective of the genre. To model these user preferences, the SME will follow reinforcement learning and will choose between exploration or exploitation.
